{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing no of API's and dictionary to store data of each API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_no = 0\n",
    "api_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    url = 'https://www.programmableweb.com/category/all/apis'\n",
    "    response  = requests.get(url)\n",
    "    data = response.text\n",
    "    #creating BeautifulSoup object with data\n",
    "    soup = BeautifulSoup(data,'html.parser')\n",
    "    apis = soup.find_all('tr',{'class':['odd','even']})\n",
    "    for api in apis:\n",
    "        name = api.find('td',{'class':'views-field views-field-pw-version-title'}).text\n",
    "        link1 = api.find('a').get('href')\n",
    "        link = 'https://www.programmableweb.com'+str(link1)\n",
    "        category = api.find('td',{'class':'views-field views-field-field-article-primary-category'}).text\n",
    "        #creating another request and BS object to get description of API\n",
    "        api_response = requests.get(link)\n",
    "        api_data = api_response.text\n",
    "        api_soup = BeautifulSoup(api_data,'html.parser')\n",
    "        api_desp1 = api_soup.find('div',{'class':'intro'}).text\n",
    "        api_desp = api_desp1[api_desp1.find(']')+1:]\n",
    "        #print('name:',name,'\\nlink:',link,'\\ncategory:',category,'\\ndescription:',api_desp,'\\n-----')\n",
    "        api_no += 1\n",
    "        #updating dictionary\n",
    "        api_dict[api_no] = [name,link,category,api_desp]\n",
    "    \n",
    "    #updating url to crawl to next pages\n",
    "    url_tag = soup.find('a',{'title':'Go to next page'})\n",
    "    if url_tag.get('href'):\n",
    "        url = 'https://www.programmableweb.com' + url_tag.get('href')\n",
    "    else:\n",
    "        break\n",
    "print(api_no)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting dictionary to Dataframe and then saving into csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_df = pd.DataFrame.from_dict(api_dict,orient = 'index',columns = ['API Name','API URL','API Category','API Decrription'])\n",
    "api_df.to_csv(r'D:\\API_List.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
